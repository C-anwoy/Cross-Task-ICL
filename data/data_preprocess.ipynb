{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = \"http://xen03.iitd.ac.in:3128\"\n",
    "os.environ['https_proxy'] = \"http://xen03.iitd.ac.in:3128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='source'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "path='target'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split='source'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392702\n"
     ]
    }
   ],
   "source": [
    "dataset_name='mnli'\n",
    "dataset= load_dataset('glue',dataset_name)['train']\n",
    "test_id=[]\n",
    "test_s1=[]\n",
    "test_s2=[]\n",
    "test_l=[]\n",
    "import random\n",
    "label2text={\n",
    "    2:'contradiction',\n",
    "    1:'neutral',\n",
    "    0:'entailment'\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "        test_id.append(d['idx'])\n",
    "        test_s1.append(d['premise'])\n",
    "        test_s2.append(d['hypothesis'])\n",
    "        test_l.append(label2text[d['label']])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence1':test_s1,\n",
    "    'sentence2':test_s2\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'007',\n",
    "        'data':test_s_df,\n",
    "        'set':'source',\n",
    "        'instruction':' Given Sentence 1 which is a premise and Sentence 2 which is a hypothesis do natural language inference on the pair. In natural language inference we mark whether the premise and hypothesis are \"neutral\", \"contradiction\" or \"entailment\". The pair are said to be \"entailed\" if the premise justifies/supports the hypothesis, if the pair contradict each other we label them as \"contradiction\" and label them \"neutral\" in all other cases'\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_train.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_train.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363846\n"
     ]
    }
   ],
   "source": [
    "dataset_name='qqp'\n",
    "dataset= load_dataset('glue',dataset_name)['train']\n",
    "test_id=[]\n",
    "test_s1=[]\n",
    "test_s2=[]\n",
    "test_l=[]\n",
    "import random\n",
    "label2text={\n",
    "    1:'duplicate',\n",
    "    0:'not duplicate'\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "        test_id.append(d['idx'])\n",
    "        test_s1.append(d['question1'])\n",
    "        test_s2.append(d['question2'])\n",
    "        test_l.append(label2text[d['label']])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence1':test_s1,\n",
    "    'sentence2':test_s2\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'002',\n",
    "        'data':test_s_df,\n",
    "        'instruction':'Given two question pairs do text classification based on whether they are duplicates or not. The questions are mined from the popular online discussion forum Quora. As duplicate quetion might be present on Quora, the task is to label two identical questions as \"duplicate\" if they ask the same query else label the pair as \"not duplicate\".',\n",
    "        'set':'source'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_train.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_train.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9427\n"
     ]
    }
   ],
   "source": [
    "dataset_name='boolq'\n",
    "dataset= load_dataset(dataset_name)['train']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_c=[]\n",
    "test_l=[]\n",
    "id=1\n",
    "import random\n",
    "\n",
    "\n",
    "for d in dataset:\n",
    "        test_id.append(id)\n",
    "        id+=1\n",
    "        test_s.append(d['question'])\n",
    "        test_c.append(d['passage'])\n",
    "        test_l.append(d['answer'])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s,\n",
    "    'context':test_c\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'003',\n",
    "        'data':test_s_df,\n",
    "        'instruction':'Given a context and a question do binary true and false type text classification. You are given a passage as context and a question related to the passage that can be answered as \"True\" or \"False\". Based on the context, question and your reasoning ability answer in a \"True\" and \"False\".',\n",
    "        'set':'source'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_train.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_train.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colll_NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041\n"
     ]
    }
   ],
   "source": [
    "dataset_name='conll2003'\n",
    "dataset= load_dataset(dataset_name)['train']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "id=1\n",
    "import random\n",
    "\n",
    "label2text={0:'O', \n",
    "1:'B-PER', \n",
    "2:'I-PER',\n",
    "3:'B-ORG',\n",
    "4:'I-ORG',\n",
    "5:'B-LOC',\n",
    "6:'I-LOC',\n",
    "7:'B-MISC',\n",
    "8:'I-MISC'\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "\n",
    "    l=[]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "    test_id.append(d['id'])\n",
    "    for i in d['ner_tags']:\n",
    "        l.append(label2text[i])\n",
    "    test_s.append(' '.join(d['tokens']))\n",
    "    test_l.append(' '.join(l))\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'004',\n",
    "        'data':test_s_df,\n",
    "        'instruction':'Given a sentence do token classification on it seek to locate and classify named entities mentioned in the sentence provided. The pre-defined named entity categories along with there labeles are Person (PER), Location (LOC), Organization (ORG) and Miscellaneous (MIS). If the token is not an entity mark it as None. As the entity is more than two tokens long use the prefix B with the named entity token to represent the beginning and  use the prefix I till the entity ends.',\n",
    "        'set':'source'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_ner_train.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_ner_train.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conll-POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041\n"
     ]
    }
   ],
   "source": [
    "dataset_name='conll2003'\n",
    "dataset= load_dataset(dataset_name)['train']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "id=1\n",
    "import random\n",
    "\n",
    "label={'\"': 0, \"''\": 1, '#': 2, '$': 3, '(': 4, ')': 5, ',': 6, '.': 7, ':': 8, '``': 9, 'CC': 10, 'CD': 11, 'DT': 12,\n",
    " 'EX': 13, 'FW': 14, 'IN': 15, 'JJ': 16, 'JJR': 17, 'JJS': 18, 'LS': 19, 'MD': 20, 'NN': 21, 'NNP': 22, 'NNPS': 23,\n",
    " 'NNS': 24, 'NN|SYM': 25, 'PDT': 26, 'POS': 27, 'PRP': 28, 'PRP$': 29, 'RB': 30, 'RBR': 31, 'RBS': 32, 'RP': 33,\n",
    " 'SYM': 34, 'TO': 35, 'UH': 36, 'VB': 37, 'VBD': 38, 'VBG': 39, 'VBN': 40, 'VBP': 41, 'VBZ': 42, 'WDT': 43,\n",
    " 'WP': 44, 'WP$': 45, 'WRB': 46}\n",
    "\n",
    "\n",
    "label2text=dict([(v,k) for k,v in label.items()])\n",
    "\n",
    "\n",
    "for d in dataset:\n",
    "\n",
    "    l=[]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "    test_id.append(d['id'])\n",
    "    for i in d['pos_tags']:\n",
    "        l.append(label2text[i])\n",
    "    test_s.append(' '.join(d['tokens']))\n",
    "    test_l.append(' '.join(l))\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'004',\n",
    "        'data':test_s_df,\n",
    "        'instruction':'Given a sentence do token classification by doing Part-of-speech (POS) tagging, which is a process in natural language processing (NLP) where each word in a text is labeled with its corresponding part of speech. This can include nouns, verbs, adjectives, and other grammatical categories.',\n",
    "        'set':'source'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_pos_train.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_pos_train.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commonsense_QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='commonsense_qa'\n",
    "dataset= load_dataset('commonsense_qa')['validation']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "\n",
    "text2label={\n",
    "    'A':0,\n",
    "    'B':1,\n",
    "    'C':2,\n",
    "    'D':3,\n",
    "    'E':4\n",
    "}\n",
    "\n",
    "label2text={\n",
    "    0:'\\nA. ',\n",
    "    1:'\\nB. ',\n",
    "    2:'\\nC. ',\n",
    "    3:'\\nD. ',\n",
    "    4:'\\nE. '\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "    test_id.append(d['id'])\n",
    "    test_l.append([d['answerKey']])\n",
    "\n",
    "    q=d['question']\n",
    "    for i,a in enumerate(d['choices']['text']):\n",
    "        q+=' '+label2text[i]+a\n",
    "\n",
    "    test_s.append(q)\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'005',\n",
    "        'data':test_s_df,\n",
    "        'instruction':'The following task relates to commonsense reasoning. It consists of a question that can be easily solved using logical abilities and reasoning, a set of five options  \"A.\", \"B.\", \"C.\", \"D.\" and \"E.\" are also provided along with the question, one of these options answers the question logically. Use your reasoning ability to select the most appropriate answer from the provided choices \"A.\", \"B.\", \"C.\", \"D.\" and \"E.\" and assign these choices (i.e  \"A.\", \"B.\", \"C.\", \"D.\" and \"E.\") as the label',  \n",
    "        'set':'source'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_train.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_train.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARC-Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2241\n"
     ]
    }
   ],
   "source": [
    "dataset_name='ARC-Easy'\n",
    "dataset= load_dataset('ai2_arc',dataset_name)['train']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "id=1\n",
    "import random\n",
    "\n",
    "label2text={\n",
    "    'A':'A',\n",
    "    'B':'B',\n",
    "    \"C\":\"C\",\n",
    "    \"D\":\"D\",\n",
    "    '2':'A',\n",
    "    '1':'B',\n",
    "    \"3\":\"C\",\n",
    "    \"4\":\"D\",\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "    if len(d['choices']['text'])!=4:\n",
    "        continue\n",
    "    test_id.append(d['id'])\n",
    "    id+=1\n",
    "    test_s.append(d['question']+'\\nA. '+d['choices']['text'][0]+'\\nB. '+d['choices']['text'][1]+'\\nC. '+d['choices']['text'][2]+'\\nD. '+d['choices']['text'][3])\n",
    "    test_l.append(label2text[d['answerKey']])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'005',\n",
    "        'data':test_s_df,\n",
    "        'instruction':'Given a question answering task from the 3rd to 9th-grade science exam. The question contains four options \"A.\", \"B.\", \"C.\" and \"D.\" Select the most appropriate choice that answers the question',\n",
    "        'set':'source'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_train.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_train.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87866\n"
     ]
    }
   ],
   "source": [
    "dataset_name='race'\n",
    "dataset= load_dataset('race','all')['train']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_c=[]\n",
    "test_l=[]\n",
    "import random\n",
    "\n",
    "\n",
    "for d in dataset:\n",
    "\n",
    "    q=d['question']+' \\nA. '+d['options'][0]+' \\nB. '+d['options'][1]+' \\nC. '+d['options'][2]+' \\nD. '+d['options'][3]\n",
    "\n",
    "    test_id.append(d['example_id'])\n",
    "    test_s.append(q)\n",
    "    test_c.append(d['article'])\n",
    "    test_l.append(d['answer'])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s,\n",
    "    'context':test_c\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'003',\n",
    "        'data':test_s_df,\n",
    "        'instruction':'Given a reading comprehension type question-answering from an english exam for school students. You are given a context and multiple choice question containing four options \"A.\", \"B.\", \"C.\" and \"D.\". The question is answerable from the comprehension. Based on the question, the option and the context select the most appropriate answer from the provided choices \"A.\", \"B.\", \"C.\" and \"D.\".',                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "        'set':'source'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_train.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_train.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AG_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n"
     ]
    }
   ],
   "source": [
    "dataset_name='ag_news'\n",
    "dataset= load_dataset(dataset_name)['train']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "id=1\n",
    "import random\n",
    "\n",
    "label2text={\n",
    "        0:'world',\n",
    "        1:'sports',\n",
    "        2:'business',\n",
    "        3:'technology'\n",
    "}\n",
    "\n",
    "\n",
    "for d in dataset:\n",
    "\n",
    "    test_id.append(id)\n",
    "    id+=1\n",
    "    test_s.append(d['text'])\n",
    "    test_l.append(label2text[d['label']])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'004',\n",
    "        'data':test_s_df,\n",
    "        'instruction':'Given a sentence do text classification, the sentence is a clipping from a news article that may be either related to sports, business, technology, or world news. You are to recognize the category of the sentence and label them as \"sports\", \"business\", \"technology\" or \"world\" news',\n",
    "        'set':'source'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_train.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_train.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67349\n"
     ]
    }
   ],
   "source": [
    "dataset_name='sst2'\n",
    "dataset= load_dataset('glue','sst2')['train']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "import random\n",
    "label2text={\n",
    "    1:'positive',\n",
    "    0:'negative'\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "        test_id.append(d['idx'])\n",
    "        test_s.append(d['sentence'])\n",
    "        test_l.append(label2text[d['label']])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'004',\n",
    "        'data':test_s_df,\n",
    "        'instruction':'Given a movie review do text classification, based on the sentiment conveyed by the review label it as \"positive\" or \"negative\"',\n",
    "        'set':'source'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_train.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_train.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=500\n",
    "split='target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_dataset(data_list, N = k):\n",
    "    \n",
    "    selected_samples = []\n",
    "\n",
    "    if type(data_list[0]['label']) == list:\n",
    "        labels = list(set([example['label'][0] for example in data_list]))\n",
    "\n",
    "        print(f\"Label Space: {labels}\")\n",
    "        count = {}\n",
    "        for label in labels:\n",
    "            count[label] = 0\n",
    "\n",
    "        np.random.seed(0)\n",
    "        chosen_indices = np.random.randint(low = 0, high = len(data_list), size = len(data_list))\n",
    "    \n",
    "        for chosen in chosen_indices:\n",
    "             \n",
    "             if (chosen not in selected_samples) and (count[data_list[chosen]['label'][0]] < (N/(len(count)))):\n",
    "                selected_samples.append(chosen)\n",
    "                count[data_list[chosen]['label'][0]] +=1\n",
    "\n",
    "        selected_samples.sort()\n",
    "\n",
    "        print(f\"Count of selected labels: {count}\")\n",
    "\n",
    "        selected_data = list(np.array(data_list)[selected_samples])\n",
    "        return selected_data, labels\n",
    "\n",
    "    else:\n",
    "        labels = list(set([example['label'] for example in data_list]))\n",
    "\n",
    "        print(f\"Label Space: {labels}\")\n",
    "        count = {}\n",
    "        for label in labels:\n",
    "            count[label] = 0\n",
    "\n",
    "        np.random.seed(0)\n",
    "        chosen_indices = np.random.randint(low = 0, high = len(data_list), size = len(data_list))\n",
    "\n",
    "        for chosen in chosen_indices:\n",
    "\n",
    "            if (chosen not in selected_samples) and (count[data_list[chosen]['label']] < (N/(len(count)))):\n",
    "                selected_samples.append(chosen)\n",
    "                count[data_list[chosen]['label']] +=1\n",
    "\n",
    "\n",
    "        selected_samples.sort()\n",
    "        print(f\"Count of selected labels: {count}\")\n",
    "        selected_data = list(np.array(data_list)[selected_samples])\n",
    "        return selected_data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Med MCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4183\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'medmcqa'\n",
    "dataset= load_dataset(dataset_name)['validation']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "\n",
    "text2label={\n",
    "    0:'A',\n",
    "    1:'B',\n",
    "    2:'C',\n",
    "    3:'D'\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "    test_id.append(d['id'])\n",
    "    test_l.append([text2label[d['cop']]])\n",
    "\n",
    "    q=d['question']+' \\nA. '+d['opa']+' \\nB. '+d['opb']+' \\nC. '+d['opc']+' \\nD. '+d['opd']\n",
    "\n",
    "    test_s.append(q)\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Space: ['B', 'A', 'D', 'C']\n",
      "Count of selected labels: {'B': 125, 'A': 125, 'D': 125, 'C': 125}\n"
     ]
    }
   ],
   "source": [
    "selected_data, labels = create_new_dataset(test_s_df)\n",
    "\n",
    "data_to_save={\n",
    "          'dataset_name': dataset_name,\n",
    "          'prompt_temp_id':'002',\n",
    "          'data': selected_data,\n",
    "          'instruction': 'Given a multiple choice question containing four options \"A.\", \"B.\", \"C.\" and \"D.\" from a medical entrance exam. The question is related to a sub-field of medical science like Microbiology, Radiology, Ophthalmology, Surgery, Human anatomy, etc. Based on the question, the option and your knowledge of the medical field select the most appropriate answer from the provided choices \"A.\", \"B.\", \"C.\" and \"D.\".',\n",
    "          'labels': labels,\n",
    "          'set':'target'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_test.json', 'w') as openfile:\n",
    "    # Reading from json file\n",
    "    json.dump(data_to_save, openfile)\n",
    "    \n",
    "for line in open(f'{split}/{dataset_name}_test.json','r'):\n",
    "    test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '45258d3d-b974-44dd-a161-c3fccbdadd88',\n",
       " 'label': ['A'],\n",
       " 'sentence': 'Which of the following is not true for myelinated nerve fibers: \\nA. Impulse through myelinated fibers is slower than non-myelinated fibers \\nB. Membrane currents are generated at nodes of Ranvier \\nC. Saltatory conduction of impulses is seen \\nD. Local anesthesia is effective only when the nerve is not covered by myelin sheath'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_set['data']))\n",
    "test_set['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'sciq'\n",
    "dataset= load_dataset(dataset_name)['test']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "id=1\n",
    "import random\n",
    "text2label={\n",
    "    'A':'distractor3',\n",
    "    'B':'distractor1',\n",
    "    'C':'distractor2',\n",
    "    'D':'correct_answer'\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "\n",
    "          k=['A','B','C','D']\n",
    "          k_=['A','B','C','D']\n",
    "          random.shuffle(k)\n",
    "          q=d['question']\n",
    "          \n",
    "          for i,l in zip(k,k_):\n",
    "                    op=text2label[i]\n",
    "                    if op=='correct_answer':\n",
    "                              test_l.append([l])\n",
    "\n",
    "                    q+=f'\\n{l}. '+d[op]\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "          test_id.append(id)\n",
    "          id+=1\n",
    "          test_s.append(q)\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Space: ['B', 'A', 'D', 'C']\n",
      "Count of selected labels: {'B': 125, 'A': 125, 'D': 125, 'C': 125}\n"
     ]
    }
   ],
   "source": [
    "selected_data, labels = create_new_dataset(test_s_df)\n",
    "\n",
    "data_to_save={\n",
    "          'dataset_name': dataset_name,\n",
    "          'prompt_temp_id':'002',\n",
    "          'data': selected_data,\n",
    "          'instruction': 'Given a question from a scientific exam about Physics, Chemistry, and Biology, among others. The question is in multiple choice format with four answer options \"A.\", \"B.\", \"C.\" and \"D.\". Using your knowledge about the scientific fields answer the question and provide the label \"A\", \"B\", \"C\" and \"D\" as answer',\n",
    "          'labels': labels,\n",
    "          'set':'target'\n",
    "\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_test.json', 'w') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_test.json','r'):\n",
    "    test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'label': ['A'],\n",
       " 'sentence': 'Compounds that are capable of accepting electrons, such as o 2 or f2, are called what?\\nA. oxidants\\nB. Oxygen\\nC. residues\\nD. antioxidants'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_set['data']))\n",
    "test_set['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARC-Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117\n"
     ]
    }
   ],
   "source": [
    "dataset_name='ARC-Challenge'\n",
    "dataset= load_dataset('ai2_arc',dataset_name)['train']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "id=1\n",
    "import random\n",
    "\n",
    "label2text={\n",
    "    'A':'A',\n",
    "    'B':'B',\n",
    "    \"C\":\"C\",\n",
    "    \"D\":\"D\",\n",
    "    '2':'A',\n",
    "    '1':'B',\n",
    "    \"3\":\"C\",\n",
    "    \"4\":\"D\",\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "    if len(d['choices']['text'])!=4:\n",
    "        continue\n",
    "    test_id.append(d['id'])\n",
    "    id+=1\n",
    "    test_s.append(d['question']+'\\nA. '+d['choices']['text'][0]+'\\nB. '+d['choices']['text'][1]+'\\nC. '+d['choices']['text'][2]+'\\nD. '+d['choices']['text'][3])\n",
    "    test_l.append(label2text[d['answerKey']])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Space: ['B', 'A', 'D', 'C']\n",
      "Count of selected labels: {'B': 125, 'A': 125, 'D': 125, 'C': 125}\n"
     ]
    }
   ],
   "source": [
    "selected_data, labels = create_new_dataset(test_s_df)\n",
    "\n",
    "data_to_save={\n",
    "        'dataset_name':dataset_name,\n",
    "        'prompt_temp_id':'005',\n",
    "        'data':selected_data,\n",
    "        'instruction':'Given a question answering task from the 3rd to 9th-grade science exam. The question contains four options \"A.\", \"B.\", \"C.\" and \"D.\" Select the most appropriate choice that answers the question',\n",
    "        'labels': labels,\n",
    "        'set':'target'\n",
    "        }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_test.json', 'w') as openfile:\n",
    "        # Reading from json file\n",
    "        json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_test.json','r'):\n",
    "        test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_415702',\n",
       " 'label': 'A',\n",
       " 'sentence': 'George wants to warm his hands quickly by rubbing them. Which skin surface will produce the most heat?\\nA. dry palms\\nB. wet palms\\nC. palms covered with oil\\nD. palms covered with lotion'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_set['data']))\n",
    "test_set['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComVE_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'comve_t1'\n",
    "df_test=pd.read_csv('raw/ComVE/subtaskA_test_data.csv').to_dict('records')\n",
    "df_test_gl=pd.read_csv('raw/ComVE/subtaskA_gold_answers.csv',names=['id','label']).set_index('id')['label'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1175,\n",
       " 'sent0': 'He loves to stroll at the park with his bed',\n",
       " 'sent1': 'He loves to stroll at the park with his dog.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "test_id=[]\n",
    "test_s1=[]\n",
    "test_s2=[]\n",
    "test_l=[]\n",
    "\n",
    "label2text={\n",
    "    0:'1',\n",
    "    1:'2'\n",
    "}\n",
    "\n",
    "\n",
    "for d in df_test:\n",
    "          test_id.append(d['id'])\n",
    "\n",
    "          test_l.append([label2text[df_test_gl[d['id']]]])\n",
    "          test_s1.append(d['sent0'])\n",
    "          test_s2.append(d['sent1'])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence1':test_s1,\n",
    "    'sentence2':test_s2\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Space: ['2', '1']\n",
      "Count of selected labels: {'2': 250, '1': 250}\n"
     ]
    }
   ],
   "source": [
    "selected_data, labels = create_new_dataset(test_s_df)\n",
    "\n",
    "data_to_save={\n",
    "          'dataset_name': dataset_name,\n",
    "          'prompt_temp_id':'004',\n",
    "          'data': selected_data,\n",
    "          'instruction': 'Given two statements \"Sentence 1\" and \"Sentence 2\". You have to decide which one makes complete logical sense. Use commonsense reasoning to identify the logically correct statement and provide the number \"1\" or \"2\" as label, corresponding to whether “Sentence 1” or “Sentence 2” is logically correct respectively.',\n",
    "          'labels': labels,\n",
    "          'set':'target'\n",
    "\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_test.json', 'w') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_test.json','r'):\n",
    "    test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 869,\n",
       " 'label': ['1'],\n",
       " 'sentence1': 'sugar is used to make coffee sour',\n",
       " 'sentence2': 'sugar is used to make coffee sweet'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_set['data']))\n",
    "test_set['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComVE_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'comve_t2'\n",
    "df_test=pd.read_csv('raw/ComVE/subtaskB_test_data.csv').to_dict('records')\n",
    "df_test_gl=pd.read_csv('raw/ComVE/subtaskB_gold_answers.csv',names=['id','label']).set_index('id')['label'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1175,\n",
       " 'FalseSent': 'He loves to stroll at the park with his bed',\n",
       " 'OptionA': 'A bed is too heavy to carry with when strolling at a park',\n",
       " 'OptionB': 'walking at a park is good for health',\n",
       " 'OptionC': 'Some beds are big while some are smaller'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "\n",
    "\n",
    "for d in df_test:\n",
    "          test_id.append(d['id'])\n",
    "\n",
    "          test_l.append([df_test_gl[d['id']]])\n",
    "          s=d['FalseSent']+ '\\n A. '+d['OptionA']+'\\n B. '+d['OptionB']+'\\n C. '+d['OptionC']\n",
    "          test_s.append(s)\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Space: ['B', 'A', 'C']\n",
      "Count of selected labels: {'B': 167, 'A': 167, 'C': 167}\n"
     ]
    }
   ],
   "source": [
    "selected_data, labels = create_new_dataset(test_s_df)\n",
    "\n",
    "data_to_save={\n",
    "          'dataset_name': dataset_name,\n",
    "          'prompt_temp_id':'001',\n",
    "          'data': selected_data,\n",
    "          'instruction': 'Given a logically wrong statement and options \"A\", \"B\" and \"C\" which try to explain why the statement is logically wrong. Select the most corresponding reason why this statement is against common sense. Provide the selected option as label amongst \"A\", \"B\" and \"C\".',\n",
    "          'labels': labels,\n",
    "          'set':'target'\n",
    "          \n",
    "          }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_test.json', 'w') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_test.json','r'):\n",
    "    test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 1175,\n",
       " 'label': ['A'],\n",
       " 'sentence': 'He loves to stroll at the park with his bed\\n A. A bed is too heavy to carry with when strolling at a park\\n B. walking at a park is good for health\\n C. Some beds are big while some are smaller'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_set['data']))\n",
    "test_set['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social_i_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1954\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'social_i_qa'\n",
    "dataset= load_dataset(dataset_name)['validation']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "test_c=[]\n",
    "id=1\n",
    "\n",
    "text2label={\n",
    "    '1':'A',\n",
    "    '2':'B',\n",
    "    '3':'C'\n",
    "}\n",
    "label2text={\n",
    "    1:'answerA',\n",
    "    2:'answerB',\n",
    "    3:'answerC'\n",
    "}\n",
    "\n",
    "\n",
    "for d in dataset:\n",
    "          test_id.append(id)\n",
    "          id+=1\n",
    "\n",
    "          test_l.append([text2label[d['label']]])\n",
    "          test_c.append(d['context'])\n",
    "\n",
    "          q=d['question']+' \\nA. '+d['answerA']+' \\nB. '+d['answerB']+' \\nC. '+d['answerC']\n",
    "          test_s.append(q)\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s,\n",
    "    'context':test_c\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Space: ['B', 'A', 'C']\n",
      "Count of selected labels: {'B': 167, 'A': 167, 'C': 167}\n"
     ]
    }
   ],
   "source": [
    "selected_data, labels = create_new_dataset(test_s_df)\n",
    "\n",
    "data_to_save={\n",
    "          'dataset_name':dataset_name,\n",
    "          'prompt_temp_id':'003',\n",
    "          'data': selected_data,\n",
    "          'instruction': 'Given an action as the context and a related question, you are to answer the question based on the context using your social intelligence. The question is of multiple choice form with three options \"A\", \"B\" and \"C\". Select the most appropriate answer from the provided choices \"A\", \"B\" and \"C\".',\n",
    "          'labels': labels,\n",
    "          'set':'target'\n",
    "          \n",
    "          }\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_test.json', 'w') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_test.json','r'):\n",
    "    test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 4,\n",
       " 'label': ['A'],\n",
       " 'sentence': \"How would Jordan feel afterwards? \\nA. horrible that he let his friends down on the camping trip \\nB. happy that he doesn't need to do the cooking on the trip \\nC. very proud and accomplished about the camping trip\",\n",
       " 'context': 'Jordan was in charge of taking the food on the camping trip and left all the food at home.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_set['data']))\n",
    "test_set['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Pharasebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2264\n"
     ]
    }
   ],
   "source": [
    "dataset_name='financial_phrasebank'\n",
    "dataset= load_dataset(dataset_name,'sentences_allagree')['train']\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "id=1\n",
    "\n",
    "text2label={\n",
    "    1:'neutral',\n",
    "    2:'positive',\n",
    "    0:'negative'\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "          test_id.append(id)\n",
    "          id+=1\n",
    "          test_s.append(d['sentence'])\n",
    "          test_l.append(text2label[d['label']])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Space: ['negative', 'neutral', 'positive']\n",
      "Count of selected labels: {'negative': 167, 'neutral': 167, 'positive': 167}\n"
     ]
    }
   ],
   "source": [
    "selected_data, labels = create_new_dataset(test_s_df)\n",
    "\n",
    "data_to_save={\n",
    "          'dataset_name': dataset_name,\n",
    "          'prompt_temp_id':'001',\n",
    "          'data': selected_data,\n",
    "          'instruction': 'Given a sentence mined from a financial news article, you are to determine the sentiment polarity of the sentence. The task deals with financial sentiment analysis. Based on the sentiment conveyed by the sentence, label the sentence as \"negative\", \"positive\" or \"neutral\"',\n",
    "          'labels': labels,\n",
    "          'set':'target'\n",
    "\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_test.json', 'w') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_test.json','r'):\n",
    "    test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 4,\n",
       " 'label': 'positive',\n",
       " 'sentence': 'Operating profit rose to EUR 13.1 mn from EUR 8.7 mn in the corresponding period in 2007 representing 7.7 % of net sales .'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_set['data']))\n",
    "test_set['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scicite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8194\n"
     ]
    }
   ],
   "source": [
    "dataset_name='scicite'\n",
    "dataset = load_dataset(f'allenai/{dataset_name}')['train']\n",
    "\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "id=1\n",
    "\n",
    "label2text={\n",
    "    0:'method',\n",
    "    1:'background',\n",
    "    2:'result'\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "    test_id.append(d['id'])\n",
    "    id+=1\n",
    "    test_s.append(d['string'].replace(\"\\n\", \" \"))\n",
    "    test_l.append(label2text[d['label']])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "\n",
    "print(len(test_s_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Space: ['result', 'background', 'method']\n",
      "Count of selected labels: {'result': 167, 'background': 167, 'method': 167}\n"
     ]
    }
   ],
   "source": [
    "selected_data, labels = create_new_dataset(test_s_df)\n",
    "\n",
    "data_to_save={\n",
    "          'dataset_name': dataset_name,\n",
    "          'prompt_temp_id':'004',\n",
    "          'data': selected_data,\n",
    "          'instruction': 'Given a sentence from scientific academic papers in which other papers are cited. You need to classify the citation intent in the sentence. Based on whether the citations are done related to methodology, result or just as background work, label the sentence as \"method\", \"result\" or \"background\" respectively.',\n",
    "          'labels': labels,\n",
    "          'set':'target'\n",
    "\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_test.json', 'w') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_test.json','r'):\n",
    "    test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '0c84e9852f312bb9b0dfd1955ebc3cf56123bf94>2dce7fc0c967c8938391c54b4cde6b377d49175a',\n",
       " 'label': 'background',\n",
       " 'sentence': 'Matricellular proteins are thought to contribute to the organization and biomechanical stability of the ECM by modulating cell-matrix interactions and cell signaling rather than by serving directly as structural components (Bornstein et al., 2000).'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_set['data']))\n",
    "test_set['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical-Abstracts-TC-Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'medical-abstracts-tc'\n",
    "\n",
    "df_test=pd.read_csv('raw/Medical-Abstracts-TC/medical_tc_test.csv').to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'condition_label': 3,\n",
       " 'medical_abstract': 'Obstructive sleep apnea following topical oropharyngeal anesthesia in loud snorers. Previous studies support the presence of an upper airway reflex mechanism that contributes to the maintenance of upper airway patency during sleep. We investigated the possibility that interference with this reflex mechanism contributes to the development of obstructive sleep apnea. Eight otherwise asymptomatic snorers (seven male and one female), age 39 +/- 5.3 yr (mean +/- SEM), underwent overnight sleep studies on three successive nights. An acclimatization night was followed by two study nights randomly assigned to control (C) and oropharyngeal anesthesia (OPA). On the OPA night topical anesthesia was induced using 10% lidocaine spray and 0.25% bupivacaine gargle. A saline placebo was used on night C. All subjects slept well on both study nights (mean sleep duration was 6.2 h on both study nights), and sleep stage distribution was similar on both nights. Obstructive apneas and hypopneas (OAH) rose from 114 +/- 43 during C to 170 +/- 49 during OPA (p less than 0.02). Central apneas and hypopneas (CAH) were unchanged between the two nights (8 +/- 4.9 versus 7 +/- 3). The duration of OAH was similar on both study nights (20 +/- 1.9 s during C versus 20 +/- 1.5 s during OPA). The frequency of movement arousals terminating OAH tended to be higher during OPA (7 +/- 2.9/h) than during C (3 +/- 0.7); P = NS. The frequency of oxyhemoglobin desaturations was also higher during OPA (5 +/- 2.1/h) than during C (3 +/- 1.4), p less than 0.07. '}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2888\n"
     ]
    }
   ],
   "source": [
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "\n",
    "id=1\n",
    "\n",
    "label2text={\n",
    "    1:'neoplasms',\n",
    "    2:'digestive system diseases',\n",
    "    3:'nervous system diseases',\n",
    "    4: 'cardiovascular diseases',\n",
    "    5: 'general pathological conditions'\n",
    "}\n",
    "\n",
    "\n",
    "for d in df_test:\n",
    "          test_id.append(id)\n",
    "          id+=1\n",
    "\n",
    "          test_l.append(label2text[d['condition_label']])\n",
    "\n",
    "          test_s.append(d['medical_abstract'])\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "test_df=pd.DataFrame(df)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Space: ['neoplasms', 'nervous system diseases', 'digestive system diseases', 'cardiovascular diseases', 'general pathological conditions']\n",
      "Count of selected labels: {'neoplasms': 100, 'nervous system diseases': 100, 'digestive system diseases': 100, 'cardiovascular diseases': 100, 'general pathological conditions': 100}\n"
     ]
    }
   ],
   "source": [
    "selected_data, labels = create_new_dataset(test_s_df)\n",
    "\n",
    "data_to_save={\n",
    "          'dataset_name': dataset_name,\n",
    "          'prompt_temp_id':'004',\n",
    "          'data': selected_data,\n",
    "          'instruction': 'Given sentences from medical abstracts describing the current medical conditions of a patient. You need to classify the given sentences based on the class of the medical problem or medical condition described in the abstract. The label should be one among \"neoplasms\", \"nervous system diseases\", \"digestive system diseases\", \"cardiovascular diseases\", \"general pathological conditions\" based on the medical condition described in the sentence.',\n",
    "          'labels': labels,\n",
    "          'set':'target'\n",
    "\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_test.json', 'w') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_test.json','r'):\n",
    "    test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'label': 'nervous system diseases',\n",
       " 'sentence': 'Obstructive sleep apnea following topical oropharyngeal anesthesia in loud snorers. Previous studies support the presence of an upper airway reflex mechanism that contributes to the maintenance of upper airway patency during sleep. We investigated the possibility that interference with this reflex mechanism contributes to the development of obstructive sleep apnea. Eight otherwise asymptomatic snorers (seven male and one female), age 39 +/- 5.3 yr (mean +/- SEM), underwent overnight sleep studies on three successive nights. An acclimatization night was followed by two study nights randomly assigned to control (C) and oropharyngeal anesthesia (OPA). On the OPA night topical anesthesia was induced using 10% lidocaine spray and 0.25% bupivacaine gargle. A saline placebo was used on night C. All subjects slept well on both study nights (mean sleep duration was 6.2 h on both study nights), and sleep stage distribution was similar on both nights. Obstructive apneas and hypopneas (OAH) rose from 114 +/- 43 during C to 170 +/- 49 during OPA (p less than 0.02). Central apneas and hypopneas (CAH) were unchanged between the two nights (8 +/- 4.9 versus 7 +/- 3). The duration of OAH was similar on both study nights (20 +/- 1.9 s during C versus 20 +/- 1.5 s during OPA). The frequency of movement arousals terminating OAH tended to be higher during OPA (7 +/- 2.9/h) than during C (3 +/- 0.7); P = NS. The frequency of oxyhemoglobin desaturations was also higher during OPA (5 +/- 2.1/h) than during C (3 +/- 1.4), p less than 0.07. '}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_set['data']))\n",
    "test_set['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLURB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'BLURB'\n",
    "dataset = load_dataset(f'EMBO/{dataset_name}', 'BC2GM-IOB')['train']\n",
    "\n",
    "test_id=[]\n",
    "test_s=[]\n",
    "test_l=[]\n",
    "\n",
    "text2label={0:'O', \n",
    "1:'B-GENE', \n",
    "2:'I-GENE'\n",
    "}\n",
    "\n",
    "for d in dataset:\n",
    "    l=[]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "    test_id.append(d['id'])\n",
    "    for i in d['ner_tags']:\n",
    "        l.append(text2label[i])\n",
    "    test_s.append(' '.join(d['tokens']))\n",
    "    test_l.append(' '.join(l))\n",
    "\n",
    "df={\n",
    "    'id':test_id,\n",
    "    'label':test_l,\n",
    "    'sentence':test_s\n",
    "}\n",
    "\n",
    "test_df=pd.DataFrame(df)\n",
    "test_df=test_df.sample(k, random_state=0)\n",
    "test_s_df=test_df.to_dict('records')\n",
    "print(len(test_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-GENE', 'I-GENE']\n"
     ]
    }
   ],
   "source": [
    "labels = list(text2label.values())\n",
    "print(labels)\n",
    "\n",
    "data_to_save={\n",
    "          'dataset_name': dataset_name,\n",
    "          'prompt_temp_id':'004',\n",
    "          'data': test_s_df,\n",
    "          'instruction': 'Given a sentence from bio-medical corpora, you are to perform a Named-Entity Recognition task and identify tokens with gene name mentions. Label each token in the sentence from one among \"O\", \"B-GENE\" and \"I-GENE\" and give the sequence of labels as output. The token from which the mention of a gene starts is to be labeled as \"B-GENE\" and the consecutive tokens till the gene name ends are to be labeled as \"I-GENE\". All other tokens which do not mention any gene name are to be labeled as \"O\".',\n",
    "          'labels': labels,\n",
    "          'set':'target'\n",
    "\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{split}/{dataset_name}_test.json', 'w') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json.dump(data_to_save, openfile)\n",
    "for line in open(f'{split}/{dataset_name}_test.json','r'):\n",
    "    test_set=json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '4482',\n",
       " 'label': 'O O O O O B-GENE I-GENE I-GENE I-GENE I-GENE I-GENE O O O O O O O O O',\n",
       " 'sentence': 'A cDNA encoding a putative RNA and / or DNA helicase has been isolated from Arabidopsis thaliana cDNA libraries .'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_set['data']))\n",
    "test_set['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
