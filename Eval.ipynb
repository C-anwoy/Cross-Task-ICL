{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "result_path='results/dataset_name={}/sourcce_dataset={}-model={}-method={}-shots={}.csv'\n",
    "def eval(dataset_name, source_dataset, model='kglm_text_davinci_003', method='totally-cross-sim', k=1):\n",
    "    r=[]\n",
    "    df=pd.read_csv(result_path.format(dataset_name,source_dataset,model,method,k))\n",
    "    df=df.fillna('')\n",
    "    output=list(df['pred'])\n",
    "    gold=np.array(df['true_label'])\n",
    "    gold=[str(o).lower() for o in gold]\n",
    "    \n",
    "    output=[str(o).replace('Label:','') for o in output]\n",
    "    output = [o.strip(' .[]\":\\'').lower() for o in output]\n",
    "    output = [o.split('.')[0] for o in output]\n",
    "    output = [o.split(',')[0] for o in output]\n",
    "    output = [o.split(':')[0] for o in output]\n",
    "    output = [o.split('-')[0] for o in output]\n",
    "    \n",
    "    output = np.array(output)\n",
    "    acc=np.mean(output==gold)*100\n",
    "    print(f\"Acc for {dataset_name} using {source_dataset} is \",acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_tasks=['ARC-Easy','ag_news','boolq','commonsense_qa','conll2003_pos','conll2003_ner','mnli','qqp','race','sst2']\n",
    "# target_tasks=['ARC-Challenge','financial_phrasebank','medmcqa','sciq','social_i_qa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adjust the 'model' argument to the function `eval` appropriately in the succeeding experiments to get results for the required model. Check the model name from the path of the generated csv file in results folder. Use `method='totally-cross-sim'` for `eval` function to get cross-task results, and `method='zero-shot'` to get zero-shot accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='_home_models_savedModels_Llama-2-7b-hf_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARC-Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc for ARC-Challenge using None is  4.6\n",
      "##################################################\n",
      "Acc for ARC-Challenge using ARC-Easy is  43.6\n",
      "Acc for ARC-Challenge using ag_news is  33.6\n",
      "Acc for ARC-Challenge using boolq is  35.0\n",
      "Acc for ARC-Challenge using commonsense_qa is  43.6\n",
      "Acc for ARC-Challenge using conll2003_pos is  33.6\n",
      "Acc for ARC-Challenge using conll2003_ner is  34.0\n",
      "Acc for ARC-Challenge using mnli is  34.2\n",
      "Acc for ARC-Challenge using qqp is  36.4\n",
      "Acc for ARC-Challenge using race is  42.8\n",
      "Acc for ARC-Challenge using sst2 is  33.2\n"
     ]
    }
   ],
   "source": [
    "eval('ARC-Challenge','None', model=model, method='zero-shot', k=0)\n",
    "print(\"#\"*50)\n",
    "for source in source_tasks: \n",
    "    eval('ARC-Challenge', source, model=model, method='totally-cross-sim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial_phrasebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc for financial_phrasebank using None is  34.3313373253493\n",
      "##################################################\n",
      "Acc for financial_phrasebank using ARC-Easy is  43.51297405189621\n",
      "Acc for financial_phrasebank using ag_news is  62.07584830339321\n",
      "Acc for financial_phrasebank using boolq is  40.91816367265469\n",
      "Acc for financial_phrasebank using commonsense_qa is  14.570858283433132\n",
      "Acc for financial_phrasebank using conll2003_pos is  0.39920159680638717\n",
      "Acc for financial_phrasebank using conll2003_ner is  0.39920159680638717\n",
      "Acc for financial_phrasebank using mnli is  62.6746506986028\n",
      "Acc for financial_phrasebank using qqp is  44.71057884231537\n",
      "Acc for financial_phrasebank using race is  53.49301397205589\n",
      "Acc for financial_phrasebank using sst2 is  65.06986027944112\n"
     ]
    }
   ],
   "source": [
    "#zero-shot \n",
    "eval('financial_phrasebank','None', model=model, method='zero-shot', k=0)\n",
    "print(\"#\"*50)\n",
    "#1-shot cross-task\n",
    "for source in source_tasks: \n",
    "    eval('financial_phrasebank', source, model=model, method='totally-cross-sim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medmcqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc for medmcqa using None is  4.2\n",
      "##################################################\n",
      "Acc for medmcqa using ARC-Easy is  31.4\n",
      "Acc for medmcqa using ag_news is  26.8\n",
      "Acc for medmcqa using boolq is  28.000000000000004\n",
      "Acc for medmcqa using commonsense_qa is  33.0\n",
      "Acc for medmcqa using conll2003_pos is  26.200000000000003\n",
      "Acc for medmcqa using conll2003_ner is  24.0\n",
      "Acc for medmcqa using mnli is  23.0\n",
      "Acc for medmcqa using qqp is  26.0\n",
      "Acc for medmcqa using race is  31.6\n",
      "Acc for medmcqa using sst2 is  23.200000000000003\n"
     ]
    }
   ],
   "source": [
    "#zero-shot \n",
    "eval('medmcqa','None', model=model, method='zero-shot', k=0)\n",
    "print(\"#\"*50)\n",
    "#1-shot cross-task\n",
    "for source in source_tasks: \n",
    "    eval('medmcqa', source, model=model, method='totally-cross-sim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sciq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc for sciq using None is  8.0\n",
      "##################################################\n",
      "Acc for sciq using ARC-Easy is  59.0\n",
      "Acc for sciq using ag_news is  45.4\n",
      "Acc for sciq using boolq is  49.0\n",
      "Acc for sciq using commonsense_qa is  65.60000000000001\n",
      "Acc for sciq using conll2003_pos is  34.4\n",
      "Acc for sciq using conll2003_ner is  26.8\n",
      "Acc for sciq using mnli is  44.800000000000004\n",
      "Acc for sciq using qqp is  25.4\n",
      "Acc for sciq using race is  64.4\n",
      "Acc for sciq using sst2 is  39.0\n"
     ]
    }
   ],
   "source": [
    "#zero-shot \n",
    "eval('sciq','None', model=model, method='zero-shot', k=0)\n",
    "print(\"#\"*50)\n",
    "#1-shot cross-task\n",
    "for source in source_tasks: \n",
    "    eval('sciq', source, model=model, method='totally-cross-sim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social_i_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc for social_i_qa using None is  41.11776447105788\n",
      "##################################################\n",
      "Acc for social_i_qa using ARC-Easy is  44.31137724550898\n",
      "Acc for social_i_qa using ag_news is  40.119760479041915\n",
      "Acc for social_i_qa using boolq is  40.31936127744511\n",
      "Acc for social_i_qa using commonsense_qa is  48.50299401197605\n",
      "Acc for social_i_qa using conll2003_pos is  38.92215568862276\n",
      "Acc for social_i_qa using conll2003_ner is  39.12175648702595\n",
      "Acc for social_i_qa using mnli is  38.92215568862276\n",
      "Acc for social_i_qa using qqp is  39.72055888223553\n",
      "Acc for social_i_qa using race is  49.101796407185624\n",
      "Acc for social_i_qa using sst2 is  39.321357285429144\n"
     ]
    }
   ],
   "source": [
    "#zero-shot \n",
    "eval('social_i_qa','None', model=model, method='zero-shot', k=0)\n",
    "print(\"#\"*50)\n",
    "#1-shot cross-task\n",
    "for source in source_tasks: \n",
    "    eval('social_i_qa', source, model=model, method='totally-cross-sim')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
